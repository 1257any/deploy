{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,sys,time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "#from sklearn.calibration import calibration_curve\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,\\\n",
    "recall_score,roc_curve,auc,cohen_kappa_score,matthews_corrcoef,classification_report\n",
    "\n",
    "from utils_multiclass_classifier import *\n",
    "#from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "from model_multiclass import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import joblib\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##====================================================================================\n",
    "project = \"NCI\"\n",
    "save_trained_model = True\n",
    "super_class = \"_10class\"\n",
    "#try:\n",
    "#    model_name = sys.argv[1]\n",
    "#except:\n",
    "model_name = \"LR\"\n",
    "\n",
    "result_dir = f\"results_{model_name}/\"\n",
    "path2meta = \"../10methylation_meta/\"\n",
    "\n",
    "os.makedirs(result_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1796,)\n"
     ]
    }
   ],
   "source": [
    "##====================================================================================\n",
    "## load data\n",
    "df_data = pd.read_csv(f\"../10methylation_meta/{project}_slide_selected{super_class}.csv\")\n",
    "df_dict = pd.read_csv(f\"../10methylation_meta/NCI_dict{super_class}.csv\")\n",
    "\n",
    "class_names = df_dict[\"DBTA_name\"].values\n",
    "actual_names = df_data[\"DBTA_name\"].values\n",
    "actual_idxs = np.array([np.argwhere(class_names == x)[0][0] for x in actual_names])\n",
    "\n",
    "y = actual_idxs\n",
    "\n",
    "X_cont = df_data[\"age\"].values\n",
    "print(X_cont.shape)\n",
    "\n",
    "X2 = df_data[\"location_idx\"].values\n",
    "X3 = df_data[\"sex_idx\"].values\n",
    "\n",
    "X2_onehot = OneHotEncoder().fit_transform(X2.reshape((-1,1))).toarray()\n",
    "#X3_onehot = OneHotEncoder().fit_transform(X3.reshape((-1,1))).toarray()\n",
    "\n",
    "X_onehot = np.hstack([X2_onehot, X2.reshape(-1,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: LR\n"
     ]
    }
   ],
   "source": [
    "##====================================================================================\n",
    "## model\n",
    "model, hyper_parameters = multi_class(model_name)\n",
    "\n",
    "# Create grid search using cross validation\n",
    "gcv = GridSearchCV(model, hyper_parameters, \n",
    "                   scoring='f1_micro',\n",
    "                   #scoring='ovr',\n",
    "                   cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ik_fold: 0\n",
      "(1438, 8) (1438,)\n",
      "best_hyper_parameters: {'C': 20.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "acc: 0.6480446927374302\n",
      "ik_fold: 1\n",
      "(1435, 8) (1435,)\n",
      "best_hyper_parameters: {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "acc: 0.6842105263157895\n",
      "ik_fold: 2\n",
      "(1437, 8) (1437,)\n",
      "best_hyper_parameters: {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "acc: 0.6295264623955432\n",
      "ik_fold: 3\n",
      "(1435, 8) (1435,)\n",
      "best_hyper_parameters: {'C': 20.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "acc: 0.6869806094182825\n",
      "ik_fold: 4\n",
      "(1439, 8) (1439,)\n",
      "best_hyper_parameters: {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "acc: 0.6722689075630253\n",
      "acc_all: 0.6642538975501113\n"
     ]
    }
   ],
   "source": [
    "##====================================================================================\n",
    "## patient split\n",
    "train_valid_test_idx = np.load(f\"{path2meta}{project}_train_valid_test_idx{super_class}.npz\", allow_pickle=True)\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "#sc = StandardScaler()\n",
    "\n",
    "#ik_fold = 0\n",
    "il_fold = 0\n",
    "for iik, ik_fold in enumerate(np.arange(5)):\n",
    "    print(\"ik_fold:\", ik_fold)\n",
    "\n",
    "    train_idx = train_valid_test_idx[\"train_idx\"][ik_fold][il_fold]\n",
    "    valid_idx = train_valid_test_idx[\"valid_idx\"][ik_fold][il_fold]\n",
    "    test_idx = train_valid_test_idx[\"test_idx\"][ik_fold]\n",
    "\n",
    "    train_idx = np.hstack((train_idx, valid_idx))\n",
    "\n",
    "    X_cont_train, X_onehot_train, y_train = X_cont[train_idx], X_onehot[train_idx], y[train_idx]\n",
    "    X_cont_test, X_onehot_test, y_test = X_cont[test_idx], X_onehot[test_idx], y[test_idx]\n",
    "\n",
    "    X_cont_train = sc.fit_transform(X_cont_train.reshape(-1,1))\n",
    "    X_cont_test = sc.transform(X_cont_test.reshape(-1,1))\n",
    "\n",
    "    X_train = np.hstack([X_cont_train, X_onehot_train])\n",
    "    X_test = np.hstack([X_cont_test, X_onehot_test])\n",
    "    \n",
    "    print(X_train.shape, y_train.shape)\n",
    "\n",
    "    ## Fit grid search\n",
    "    best_model = gcv.fit(X_train, y_train)\n",
    "\n",
    "    if save_trained_model:\n",
    "        joblib.dump(sc, f\"{result_dir}sc_trained_{ik_fold}.joblib\")\n",
    "        joblib.dump(best_model.best_estimator_, f\"{result_dir}trained_model_{ik_fold}.joblib\")\n",
    "\n",
    "    ##---------------------------------\n",
    "    ## best hyper parameters\n",
    "    print('best_hyper_parameters:', best_model.best_params_)\n",
    "\n",
    "    results = pd.DataFrame(gcv.cv_results_).sort_values(by='mean_test_score', ascending=False)\n",
    "    results = results.loc[:, ~results.columns.str.endswith(\"_time\")]\n",
    "    results = results.loc[:, ~results.columns.str.startswith(\"split\")]\n",
    "\n",
    "    results.to_csv(f\"{result_dir}hyper_params_{ik_fold}.csv\", index=None)\n",
    "\n",
    "    ## pred and probability:\n",
    "    #y_pred = best_model.best_estimator_.predict(X_test)\n",
    "    y_prob = best_model.best_estimator_.predict_proba(X_test)\n",
    "\n",
    "    pred_idx = np.argmax(y_prob, axis=1)\n",
    "    \n",
    "    acc = np.mean(y_test == pred_idx)\n",
    "    print(\"acc:\", acc)\n",
    "    \n",
    "    if iik == 0:\n",
    "        y_test_all = y_test\n",
    "        y_prob_all = y_prob\n",
    "    else:\n",
    "        y_test_all = np.append(y_test_all, y_test)\n",
    "        y_prob_all = np.vstack([y_prob_all,y_prob])\n",
    "        \n",
    "##--------------------------\n",
    "pred_idxs = np.argmax(y_prob_all, axis=1)\n",
    "acc_all = np.mean(y_test_all == pred_idxs)\n",
    "print(\"acc_all:\", acc_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##====================================================================================\n",
    "df_meta = df_data\n",
    "\n",
    "for ik_fold in np.arange(5):\n",
    "    test_idx = train_valid_test_idx[\"test_idx\"][ik_fold]\n",
    "    \n",
    "    if ik_fold == 0:\n",
    "        test_idx_all = test_idx\n",
    "    else:\n",
    "        test_idx_all = np.hstack((test_idx_all,test_idx))\n",
    "\n",
    "df_test = df_meta.loc[test_idx_all].reset_index(drop=True)\n",
    "\n",
    "pred_names = class_names[pred_idxs]\n",
    "df_test[\"pred_name\"] = pred_names\n",
    "df_test[class_names] = y_prob_all\n",
    "\n",
    "## get the same order of slide_selected file\n",
    "df_test = df_test.sort_values(by=\"slide_name\", ignore_index=True)\n",
    "df_test.to_csv(f\"{result_dir}{model_name}_score.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f\"{result_dir}{model_name}_acc.txt\", [acc_all], fmt=\"%s\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
